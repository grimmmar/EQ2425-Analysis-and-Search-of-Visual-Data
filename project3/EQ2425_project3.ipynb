{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jASwkW5tiN_-"
      },
      "source": [
        "# EQ2425 Analysis and Search of Visual Data-Project 3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZbczbSFuLNB"
      },
      "source": [
        "Hanqi Yang hanqi@kth.se\n",
        "\n",
        "Qian Zhou qianzho@kth.se"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3gJuroC1jMj"
      },
      "source": [
        "# Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsKED7aI1jMj",
        "outputId": "5d0896c1-025b-4cac-a023-fb8f699f5792"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ipython-autotime\n",
            "  Downloading ipython_autotime-0.3.1-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipython-autotime) (7.9.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (57.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.0.10)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.6.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (5.1.1)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 14.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->ipython-autotime) (0.8.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->ipython-autotime) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->ipython-autotime) (0.7.0)\n",
            "Installing collected packages: jedi, ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.1 jedi-0.18.1\n",
            "time: 529 µs (started: 2022-10-13 18:48:11 +00:00)\n"
          ]
        }
      ],
      "source": [
        "!pip install ipython-autotime\n",
        "\n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Z9ZCc0nf1k0x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c836b4c4-f529-4c2c-cb3d-3e8aec0a6976"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "time: 18.6 s (started: 2022-10-13 18:48:14 +00:00)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHc2iUkDhmwY",
        "outputId": "d5008319-1361-4b97-ee34-8d11c8d7ac7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.09 s (started: 2022-10-13 18:48:39 +00:00)\n"
          ]
        }
      ],
      "source": [
        "import torch \n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary\n",
        "\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJs4zSaniiNb",
        "outputId": "46626285-3a60-407f-e6aa-ef672a42a33e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "time: 65.9 ms (started: 2022-10-13 18:48:42 +00:00)\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsL_VQmGjflS",
        "outputId": "1fb63ce9-50aa-4ff5-9f69-51e4de15b8d5",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Oct 13 18:48:44 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8     9W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "time: 117 ms (started: 2022-10-13 18:48:44 +00:00)\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEL5UFXB1jMm"
      },
      "source": [
        "# Data Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBsUjtQskyl4",
        "outputId": "ec59ff2b-eda6-44c3-e46f-cdd4634b470b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.4 ms (started: 2022-10-13 18:48:47 +00:00)\n"
          ]
        }
      ],
      "source": [
        "normalize = transforms.Normalize(mean=[.5, .5, .5], std=[1 ,1, 1])\n",
        "data_transform = transforms.Compose([transforms.ToTensor(), normalize])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "40fa23e76a6344ec8fe6a4067eca83a8",
            "e1837ad39e8c434b86622ac976a92e77",
            "9ac5984964404b26ba9a9d25c9eabd93",
            "28fd8e4bf8bb4677ac7090f88f4a14e6",
            "de9bff3824184c65b9d1ae0a03efc1e3",
            "a1e407706fda40bcb3f426deebdd6684",
            "1464a97c17584973984171f3c8ab5b60",
            "0737c44cc61042f08fdbebc6ce6860d9",
            "66d2f83990984ad0a29af087a2c33c5f",
            "f8560627d398421abc117c34b7ee3ce1",
            "0d44dad3ce1e4528bf1a80f2ac886599"
          ]
        },
        "id": "hrmV09jW1jMo",
        "outputId": "ee0f3249-c63e-451c-fbe3-f5a78a12255a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to gdrive/My Drive/cifar-10-python/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40fa23e76a6344ec8fe6a4067eca83a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting gdrive/My Drive/cifar-10-python/cifar-10-python.tar.gz to gdrive/My Drive/cifar-10-python/\n",
            "Files already downloaded and verified\n",
            "time: 11.1 s (started: 2022-10-13 18:48:48 +00:00)\n"
          ]
        }
      ],
      "source": [
        "path = 'gdrive/My Drive/cifar-10-python/'\n",
        "trainDataset = CIFAR10(root = path, train=True, transform=data_transform, download=True)\n",
        "testDataset = CIFAR10(root = path, train=False, transform=data_transform, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzKkUlpv1jMo",
        "outputId": "1aa2bda9-12f5-4784-8776-877fd9cce7a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 748 µs (started: 2022-10-13 18:49:01 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# parameter\n",
        "learning_rate = 0.1 # 5B: 0.001 or 0.1\n",
        "mini_batch = 64 # 5A: 64 or 256\n",
        "epochs = 300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJriL46h1jMp",
        "outputId": "4c40a1ad-cf22-467a-e2ed-36a412ca1eb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.62 ms (started: 2022-10-13 18:49:02 +00:00)\n"
          ]
        }
      ],
      "source": [
        "trainLoader = DataLoader(trainDataset, batch_size=mini_batch, shuffle=True) # 5C: shuffle = False or True\n",
        "testLoader = DataLoader(testDataset, batch_size=mini_batch, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20HQVOeDroKT"
      },
      "source": [
        "# CNN Construction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsikOfkw1jMp",
        "outputId": "7ed3193a-eee7-4077-9575-2712645e856b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 2.47 ms (started: 2022-10-10 14:33:42 +00:00)\n"
          ]
        }
      ],
      "source": [
        "class Net(nn.Module):\n",
        "        def __init__(self, num_class=10):\n",
        "            super(Net, self).__init__()\n",
        "            self.cnn = nn.Sequential(\n",
        "                nn.Conv2d(3, 24, kernel_size=5, stride=1, padding=0),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                \n",
        "                nn.Conv2d(24, 48, kernel_size=3, stride=1, padding=0),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                \n",
        "                nn.Conv2d(48, 96, kernel_size=3, stride=1, padding=0),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                \n",
        "                nn.Flatten(),\n",
        "                \n",
        "                nn.Linear(2*2*96, 512),\n",
        "                nn.ReLU(),\n",
        "\n",
        "                nn.Linear(512, num_class),\n",
        "                nn.Softmax())\n",
        "            \n",
        "        def forward(self, x):\n",
        "            out = self.cnn(x)\n",
        "            return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ft93B-X1r43O",
        "outputId": "52c5f377-f585-4872-cf30-ce144b73d50f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 1.98 ms (started: 2022-10-08 22:23:49 +00:00)\n"
          ]
        }
      ],
      "source": [
        "class Net4A1(nn.Module):\n",
        "        def __init__(self, num_class=10):\n",
        "            super(Net4A1, self).__init__()\n",
        "            self.cnn = nn.Sequential(\n",
        "                nn.Conv2d(3, 64, kernel_size=5, stride=1, padding=0),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                \n",
        "                nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=0),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                \n",
        "                nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=0),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                \n",
        "                nn.Flatten(),\n",
        "                \n",
        "                nn.Linear(2*2*256, 512),\n",
        "                nn.ReLU(),\n",
        "\n",
        "                nn.Linear(512, num_class),\n",
        "                nn.Softmax())\n",
        "            \n",
        "        def forward(self, x):\n",
        "            out = self.cnn(x)\n",
        "            return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMKEA57T_Bu4",
        "outputId": "d13e0d20-133a-4922-b128-5d10d2f198c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 2.88 ms (started: 2022-10-09 07:20:17 +00:00)\n"
          ]
        }
      ],
      "source": [
        "class Net4A2(nn.Module):\n",
        "        def __init__(self, num_class=10):\n",
        "            super(Net4A2, self).__init__()\n",
        "            self.cnn = nn.Sequential(\n",
        "                nn.Conv2d(3, 24, kernel_size=5, stride=1, padding=0),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                \n",
        "                nn.Conv2d(24, 48, kernel_size=3, stride=1, padding=0),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                \n",
        "                nn.Conv2d(48, 96, kernel_size=3, stride=1, padding=0),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                \n",
        "                nn.Flatten(),\n",
        "                \n",
        "                nn.Linear(2*2*96, 512),\n",
        "                nn.ReLU(),\n",
        "\n",
        "                nn.Linear(512, 128),\n",
        "                nn.ReLU(),\n",
        "\n",
        "                nn.Linear(128, num_class),\n",
        "                nn.Softmax())\n",
        "            \n",
        "        def forward(self, x):\n",
        "            out = self.cnn(x)\n",
        "            return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPde7octrzcC",
        "outputId": "bbd81e5c-50d7-43ec-c4c1-9b0efd91c8ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 2.02 ms (started: 2022-10-09 08:58:51 +00:00)\n"
          ]
        }
      ],
      "source": [
        "class Net4B(nn.Module):\n",
        "        def __init__(self, num_class=10):\n",
        "            super(Net4B, self).__init__()\n",
        "            self.cnn = nn.Sequential(\n",
        "                nn.Conv2d(3, 64, kernel_size=7, stride=1, padding=0),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                \n",
        "                nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=0),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                \n",
        "                nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=0),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                \n",
        "                nn.Flatten(),\n",
        "                \n",
        "                nn.Linear(256, 512),\n",
        "                nn.ReLU(),\n",
        "\n",
        "                nn.Linear(512, num_class),\n",
        "                nn.Softmax())\n",
        "            \n",
        "        def forward(self, x):\n",
        "            out = self.cnn(x)\n",
        "            return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccfmXiP3sVRZ",
        "outputId": "95a27c79-c0d8-4d9c-d60c-bbecfb6f5cde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 2.21 ms (started: 2022-10-09 11:20:11 +00:00)\n"
          ]
        }
      ],
      "source": [
        "class Net4C(nn.Module):\n",
        "        def __init__(self, num_class=10):\n",
        "            super(Net4C, self).__init__()\n",
        "            self.cnn = nn.Sequential(\n",
        "                nn.Conv2d(3, 64, kernel_size=5, stride=1, padding=0),\n",
        "                nn.LeakyReLU(),\n",
        "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                \n",
        "                nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=0),\n",
        "                nn.LeakyReLU(),\n",
        "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                \n",
        "                nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=0),\n",
        "                nn.LeakyReLU(),\n",
        "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                \n",
        "                nn.Flatten(),\n",
        "                \n",
        "                nn.Linear(2*2*256, 512),\n",
        "                nn.LeakyReLU(),\n",
        "\n",
        "                nn.Linear(512, num_class),\n",
        "                nn.Softmax())\n",
        "            \n",
        "        def forward(self, x):\n",
        "            out = self.cnn(x)\n",
        "            return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGlDMOHjspyw",
        "outputId": "d5c1b4ee-950d-460d-c17d-fa2b199620cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 2.82 ms (started: 2022-10-10 09:41:49 +00:00)\n"
          ]
        }
      ],
      "source": [
        "class Net4D(nn.Module):\n",
        "        def __init__(self, num_class=10):\n",
        "            super(Net4D, self).__init__()\n",
        "            self.cnn = nn.Sequential(\n",
        "                nn.Conv2d(3, 64, kernel_size=5, stride=1, padding=0),\n",
        "                nn.LeakyReLU(),\n",
        "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                \n",
        "                nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=0),\n",
        "                nn.LeakyReLU(),\n",
        "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                \n",
        "                nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=0),\n",
        "                nn.LeakyReLU(),\n",
        "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                \n",
        "                nn.Flatten(),\n",
        "                \n",
        "                nn.Linear(2*2*256, 512),\n",
        "                nn.Dropout(p=0.3),\n",
        "                nn.LeakyReLU(),\n",
        "\n",
        "                nn.Linear(512, num_class),\n",
        "                nn.Softmax())\n",
        "            \n",
        "        def forward(self, x):\n",
        "            out = self.cnn(x)\n",
        "            return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eM727yvJtBL1",
        "outputId": "3297c5f5-5be0-4cc5-fc18-9a6cb188ffe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.9 ms (started: 2022-10-13 18:49:09 +00:00)\n"
          ]
        }
      ],
      "source": [
        "class Net4E(nn.Module):\n",
        "        def __init__(self, num_class=10):\n",
        "            super(Net4E, self).__init__()\n",
        "            self.cnn = nn.Sequential(\n",
        "                nn.Conv2d(3, 64, kernel_size=5, stride=1, padding=0),\n",
        "                nn.LeakyReLU(),\n",
        "                nn.BatchNorm2d(64),\n",
        "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                \n",
        "                nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=0),\n",
        "                nn.LeakyReLU(),\n",
        "                nn.BatchNorm2d(128),\n",
        "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                \n",
        "                nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=0),\n",
        "                nn.LeakyReLU(),\n",
        "                nn.BatchNorm2d(256),\n",
        "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                \n",
        "                nn.Flatten(),\n",
        "                \n",
        "                nn.Linear(2*2*256, 512),\n",
        "                nn.Dropout(p=0.3),\n",
        "                nn.LeakyReLU(),\n",
        "                nn.BatchNorm1d(512),\n",
        "\n",
        "                nn.Linear(512, num_class),\n",
        "                nn.Softmax())\n",
        "            \n",
        "        def forward(self, x):\n",
        "            out = self.cnn(x)\n",
        "            return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHo9VB7R1jMq",
        "outputId": "10291a68-be12-4e63-ba27-805a8d65046a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 28, 28]           4,864\n",
            "         LeakyReLU-2           [-1, 64, 28, 28]               0\n",
            "       BatchNorm2d-3           [-1, 64, 28, 28]             128\n",
            "         MaxPool2d-4           [-1, 64, 14, 14]               0\n",
            "            Conv2d-5          [-1, 128, 12, 12]          73,856\n",
            "         LeakyReLU-6          [-1, 128, 12, 12]               0\n",
            "       BatchNorm2d-7          [-1, 128, 12, 12]             256\n",
            "         MaxPool2d-8            [-1, 128, 6, 6]               0\n",
            "            Conv2d-9            [-1, 256, 4, 4]         295,168\n",
            "        LeakyReLU-10            [-1, 256, 4, 4]               0\n",
            "      BatchNorm2d-11            [-1, 256, 4, 4]             512\n",
            "        MaxPool2d-12            [-1, 256, 2, 2]               0\n",
            "          Flatten-13                 [-1, 1024]               0\n",
            "           Linear-14                  [-1, 512]         524,800\n",
            "          Dropout-15                  [-1, 512]               0\n",
            "        LeakyReLU-16                  [-1, 512]               0\n",
            "      BatchNorm1d-17                  [-1, 512]           1,024\n",
            "           Linear-18                   [-1, 10]           5,130\n",
            "          Softmax-19                   [-1, 10]               0\n",
            "================================================================\n",
            "Total params: 905,738\n",
            "Trainable params: 905,738\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.83\n",
            "Params size (MB): 3.46\n",
            "Estimated Total Size (MB): 5.29\n",
            "----------------------------------------------------------------\n",
            "time: 10 s (started: 2022-10-13 18:49:12 +00:00)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:139: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        }
      ],
      "source": [
        "classes = 10\n",
        "\n",
        "net = Net4E(classes).to(device)\n",
        "summary(net, (3,32,32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKEWkkCE1jMq"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SI3uDCz1jMq",
        "outputId": "9f93a1c0-6f6f-4c4d-ce93-48a091067b44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.42 ms (started: 2022-10-13 18:49:24 +00:00)\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6k7Wbh5i1jMr",
        "outputId": "b1867129-fe0d-4673-a000-8348f1afd30d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "Training loss: 2.028758368376271\n",
            "Training Accuracy： 0.4262\n",
            "Epoch: 1\n",
            "Training loss: 1.9380218093962316\n",
            "Training Accuracy： 0.4727\n",
            "Epoch: 2\n",
            "Training loss: 1.895307657511338\n",
            "Training Accuracy： 0.5027866666666667\n",
            "Epoch: 3\n",
            "Training loss: 1.859069570251133\n",
            "Training Accuracy： 0.526805\n",
            "Epoch: 4\n",
            "Training loss: 1.8392993406871396\n",
            "Training Accuracy： 0.545276\n",
            "Epoch: 5\n",
            "Training loss: 1.8210909840700877\n",
            "Training Accuracy： 0.5606866666666667\n",
            "Epoch: 6\n",
            "Training loss: 1.80267550512348\n",
            "Training Accuracy： 0.57432\n",
            "Epoch: 7\n",
            "Training loss: 1.7918377578106073\n",
            "Training Accuracy： 0.5859575\n",
            "Epoch: 8\n",
            "Training loss: 1.7797052180370712\n",
            "Training Accuracy： 0.5963888888888889\n",
            "Epoch: 9\n",
            "Training loss: 1.766675279725848\n",
            "Training Accuracy： 0.60597\n",
            "Epoch: 10\n",
            "Training loss: 1.7546973664437413\n",
            "Training Accuracy： 0.6149636363636364\n",
            "Epoch: 11\n",
            "Training loss: 1.7396938136166624\n",
            "Training Accuracy： 0.6237583333333333\n",
            "Epoch: 12\n",
            "Training loss: 1.7365158712467574\n",
            "Training Accuracy： 0.6313953846153846\n",
            "Epoch: 13\n",
            "Training loss: 1.7268334442697217\n",
            "Training Accuracy： 0.6386414285714286\n",
            "Epoch: 14\n",
            "Training loss: 1.7194874733305343\n",
            "Training Accuracy： 0.6454333333333333\n",
            "Epoch: 15\n",
            "Training loss: 1.7086347259219041\n",
            "Training Accuracy： 0.6520225\n",
            "Epoch: 16\n",
            "Training loss: 1.7089762916345426\n",
            "Training Accuracy： 0.6578376470588235\n",
            "Epoch: 17\n",
            "Training loss: 1.7061448749678825\n",
            "Training Accuracy： 0.6631533333333334\n",
            "Epoch: 18\n",
            "Training loss: 1.6940254570578066\n",
            "Training Accuracy： 0.6685621052631578\n",
            "Epoch: 19\n",
            "Training loss: 1.6885831790506993\n",
            "Training Accuracy： 0.673691\n",
            "Epoch: 20\n",
            "Training loss: 1.682953405563179\n",
            "Training Accuracy： 0.6786190476190476\n",
            "Epoch: 21\n",
            "Training loss: 1.6795569725353698\n",
            "Training Accuracy： 0.6832545454545454\n",
            "Epoch: 22\n",
            "Training loss: 1.6738822742191422\n",
            "Training Accuracy： 0.6877356521739131\n",
            "Epoch: 23\n",
            "Training loss: 1.6729113160801665\n",
            "Training Accuracy： 0.6918925\n",
            "Epoch: 24\n",
            "Training loss: 1.6657487646393154\n",
            "Training Accuracy： 0.695996\n",
            "Epoch: 25\n",
            "Training loss: 1.6607554519877714\n",
            "Training Accuracy： 0.6999976923076923\n",
            "Epoch: 26\n",
            "Training loss: 1.6549849853186351\n",
            "Training Accuracy： 0.7039007407407407\n",
            "Epoch: 27\n",
            "Training loss: 1.6525868742972079\n",
            "Training Accuracy： 0.7076164285714286\n",
            "Epoch: 28\n",
            "Training loss: 1.6488745038771568\n",
            "Training Accuracy： 0.7112062068965517\n",
            "Epoch: 29\n",
            "Training loss: 1.645883085630129\n",
            "Training Accuracy： 0.7146486666666667\n",
            "Epoch: 30\n",
            "Training loss: 1.6373614934094423\n",
            "Training Accuracy： 0.71816\n",
            "Epoch: 31\n",
            "Training loss: 1.6354901929340704\n",
            "Training Accuracy： 0.72148875\n",
            "Epoch: 32\n",
            "Training loss: 1.633028052499532\n",
            "Training Accuracy： 0.724700606060606\n",
            "Epoch: 33\n",
            "Training loss: 1.627887366982677\n",
            "Training Accuracy： 0.7278782352941177\n",
            "Epoch: 34\n",
            "Training loss: 1.6222175359725952\n",
            "Training Accuracy： 0.7310285714285715\n",
            "Epoch: 35\n",
            "Training loss: 1.6186725091751275\n",
            "Training Accuracy： 0.7341094444444445\n",
            "Epoch: 36\n",
            "Training loss: 1.6162871683345121\n",
            "Training Accuracy： 0.7370929729729729\n",
            "Epoch: 37\n",
            "Training loss: 1.612461813727913\n",
            "Training Accuracy： 0.7400147368421053\n",
            "Epoch: 38\n",
            "Training loss: 1.6112546353693813\n",
            "Training Accuracy： 0.742814358974359\n",
            "Epoch: 39\n",
            "Training loss: 1.6086257662614594\n",
            "Training Accuracy： 0.7455415\n",
            "Epoch: 40\n",
            "Training loss: 1.6073323276341724\n",
            "Training Accuracy： 0.7481678048780488\n",
            "Epoch: 41\n",
            "Training loss: 1.6048521173884496\n",
            "Training Accuracy： 0.7507333333333334\n",
            "Epoch: 42\n",
            "Training loss: 1.5982191817229972\n",
            "Training Accuracy： 0.7533288372093023\n",
            "Epoch: 43\n",
            "Training loss: 1.604646740819487\n",
            "Training Accuracy： 0.755669090909091\n",
            "Epoch: 44\n",
            "Training loss: 1.598346682003392\n",
            "Training Accuracy： 0.7580386666666666\n",
            "Epoch: 45\n",
            "Training loss: 1.596103633151335\n",
            "Training Accuracy： 0.7603547826086956\n",
            "Epoch: 46\n",
            "Training loss: 1.5923247328194816\n",
            "Training Accuracy： 0.7626565957446808\n",
            "Epoch: 47\n",
            "Training loss: 1.5884959836445196\n",
            "Training Accuracy： 0.7649395833333333\n",
            "Epoch: 48\n",
            "Training loss: 1.5908240675926208\n",
            "Training Accuracy： 0.7670816326530612\n",
            "Epoch: 49\n",
            "Training loss: 1.5851446063927068\n",
            "Training Accuracy： 0.7692528\n",
            "Epoch: 50\n",
            "Training loss: 1.5875522582732198\n",
            "Training Accuracy： 0.7712898039215687\n",
            "Epoch: 51\n",
            "Training loss: 1.5797729850425135\n",
            "Training Accuracy： 0.7734034615384615\n",
            "Epoch: 52\n",
            "Training loss: 1.5806685725746252\n",
            "Training Accuracy： 0.7754162264150943\n",
            "Epoch: 53\n",
            "Training loss: 1.5783055237187145\n",
            "Training Accuracy： 0.777405925925926\n",
            "Epoch: 54\n",
            "Training loss: 1.5779770888635873\n",
            "Training Accuracy： 0.7793189090909091\n",
            "Epoch: 55\n",
            "Training loss: 1.573014923831081\n",
            "Training Accuracy： 0.7812607142857143\n",
            "Epoch: 56\n",
            "Training loss: 1.5724657514820928\n",
            "Training Accuracy： 0.783141052631579\n",
            "Epoch: 57\n",
            "Training loss: 1.5702341148615493\n",
            "Training Accuracy： 0.7849927586206896\n",
            "Epoch: 58\n",
            "Training loss: 1.5689719086108\n",
            "Training Accuracy： 0.7868010169491525\n",
            "Epoch: 59\n",
            "Training loss: 1.5642699876709667\n",
            "Training Accuracy： 0.78863\n",
            "Epoch: 60\n",
            "Training loss: 1.563791978999477\n",
            "Training Accuracy： 0.7903996721311476\n",
            "Epoch: 61\n",
            "Training loss: 1.5636364777984522\n",
            "Training Accuracy： 0.792121935483871\n",
            "Epoch: 62\n",
            "Training loss: 1.5591565176958928\n",
            "Training Accuracy： 0.7938619047619048\n",
            "Epoch: 63\n",
            "Training loss: 1.5590876973498509\n",
            "Training Accuracy： 0.7955484375\n",
            "Epoch: 64\n",
            "Training loss: 1.5591864965455917\n",
            "Training Accuracy： 0.7971818461538461\n",
            "Epoch: 65\n",
            "Training loss: 1.5577109059714296\n",
            "Training Accuracy： 0.798789393939394\n",
            "Epoch: 66\n",
            "Training loss: 1.5545105575905431\n",
            "Training Accuracy： 0.8003904477611941\n",
            "Epoch: 67\n",
            "Training loss: 1.552918091911794\n",
            "Training Accuracy： 0.8019735294117647\n",
            "Epoch: 68\n",
            "Training loss: 1.5541749718549\n",
            "Training Accuracy： 0.8034884057971015\n",
            "Epoch: 69\n",
            "Training loss: 1.550396047589724\n",
            "Training Accuracy： 0.8050214285714286\n",
            "Epoch: 70\n",
            "Training loss: 1.5499510614158551\n",
            "Training Accuracy： 0.806514647887324\n",
            "Epoch: 71\n",
            "Training loss: 1.551073944477169\n",
            "Training Accuracy： 0.8079491666666667\n",
            "Epoch: 72\n",
            "Training loss: 1.5487557867603838\n",
            "Training Accuracy： 0.8093769863013699\n",
            "Epoch: 73\n",
            "Training loss: 1.5492586267878636\n",
            "Training Accuracy： 0.8107591891891892\n",
            "Epoch: 74\n",
            "Training loss: 1.545154192563518\n",
            "Training Accuracy： 0.8121538666666667\n",
            "Epoch: 75\n",
            "Training loss: 1.5430453613286128\n",
            "Training Accuracy： 0.8135471052631579\n",
            "Epoch: 76\n",
            "Training loss: 1.542393113341173\n",
            "Training Accuracy： 0.8149127272727272\n",
            "Epoch: 77\n",
            "Training loss: 1.5411940186529818\n",
            "Training Accuracy： 0.8162546153846154\n",
            "Epoch: 78\n",
            "Training loss: 1.5391566561311103\n",
            "Training Accuracy： 0.8175901265822785\n",
            "Epoch: 79\n",
            "Training loss: 1.5398576858708315\n",
            "Training Accuracy： 0.81888275\n",
            "Epoch: 80\n",
            "Training loss: 1.5399258315105877\n",
            "Training Accuracy： 0.820145925925926\n",
            "Epoch: 81\n",
            "Training loss: 1.5395087723231986\n",
            "Training Accuracy： 0.8213824390243902\n",
            "Epoch: 82\n",
            "Training loss: 1.5370308243100295\n",
            "Training Accuracy： 0.82262\n",
            "Epoch: 83\n",
            "Training loss: 1.5389818210735955\n",
            "Training Accuracy： 0.8238021428571428\n",
            "Epoch: 84\n",
            "Training loss: 1.540561881059271\n",
            "Training Accuracy： 0.8249411764705883\n",
            "Epoch: 85\n",
            "Training loss: 1.5347566278389349\n",
            "Training Accuracy： 0.8261202325581395\n",
            "Epoch: 86\n",
            "Training loss: 1.533782309888269\n",
            "Training Accuracy： 0.8272864367816092\n",
            "Epoch: 87\n",
            "Training loss: 1.5324097812328192\n",
            "Training Accuracy： 0.8284365909090909\n",
            "Epoch: 88\n",
            "Training loss: 1.530815045089673\n",
            "Training Accuracy： 0.8295815730337078\n",
            "Epoch: 89\n",
            "Training loss: 1.530057306484798\n",
            "Training Accuracy： 0.8307073333333334\n",
            "Epoch: 90\n",
            "Training loss: 1.529163107695177\n",
            "Training Accuracy： 0.831818021978022\n",
            "Epoch: 91\n",
            "Training loss: 1.5295387550693034\n",
            "Training Accuracy： 0.832899347826087\n",
            "Epoch: 92\n",
            "Training loss: 1.5281968484144381\n",
            "Training Accuracy： 0.8339737634408602\n",
            "Epoch: 93\n",
            "Training loss: 1.5265143987772716\n",
            "Training Accuracy： 0.8350421276595744\n",
            "Epoch: 94\n",
            "Training loss: 1.526173406854615\n",
            "Training Accuracy： 0.8360911578947369\n",
            "Epoch: 95\n",
            "Training loss: 1.5262822859427507\n",
            "Training Accuracy： 0.8371195833333334\n",
            "Epoch: 96\n",
            "Training loss: 1.5257672783358933\n",
            "Training Accuracy： 0.8381331958762887\n",
            "Epoch: 97\n",
            "Training loss: 1.5247478259493932\n",
            "Training Accuracy： 0.8391369387755102\n",
            "Epoch: 98\n",
            "Training loss: 1.5248516055629076\n",
            "Training Accuracy： 0.8401167676767677\n",
            "Epoch: 99\n",
            "Training loss: 1.5236496131133546\n",
            "Training Accuracy： 0.8410904\n",
            "Epoch: 100\n",
            "Training loss: 1.5244513769893695\n",
            "Training Accuracy： 0.8420370297029703\n",
            "Epoch: 101\n",
            "Training loss: 1.523639080012241\n",
            "Training Accuracy： 0.8429719607843137\n",
            "Epoch: 102\n",
            "Training loss: 1.5221005181217437\n",
            "Training Accuracy： 0.8439038834951457\n",
            "Epoch: 103\n",
            "Training loss: 1.5225861415533763\n",
            "Training Accuracy： 0.8448090384615384\n",
            "Epoch: 104\n",
            "Training loss: 1.522844390338644\n",
            "Training Accuracy： 0.8456980952380952\n",
            "Epoch: 105\n",
            "Training loss: 1.5217480188440484\n",
            "Training Accuracy： 0.8465811320754717\n",
            "Epoch: 106\n",
            "Training loss: 1.5201244992978127\n",
            "Training Accuracy： 0.8474648598130841\n",
            "Epoch: 107\n",
            "Training loss: 1.518613857381484\n",
            "Training Accuracy： 0.848345\n",
            "Epoch: 108\n",
            "Training loss: 1.5201295627962292\n",
            "Training Accuracy： 0.849191376146789\n",
            "Epoch: 109\n",
            "Training loss: 1.517127283851204\n",
            "Training Accuracy： 0.8500523636363636\n",
            "Epoch: 110\n",
            "Training loss: 1.517503824227911\n",
            "Training Accuracy： 0.8508958558558558\n",
            "Epoch: 111\n",
            "Training loss: 1.5166850298871775\n",
            "Training Accuracy： 0.8517321428571428\n",
            "Epoch: 112\n",
            "Training loss: 1.515887910447767\n",
            "Training Accuracy： 0.8525582300884956\n",
            "Epoch: 113\n",
            "Training loss: 1.5157346823026456\n",
            "Training Accuracy： 0.8533719298245614\n",
            "Epoch: 114\n",
            "Training loss: 1.5152577067275181\n",
            "Training Accuracy： 0.8541758260869565\n",
            "Epoch: 115\n",
            "Training loss: 1.5134432733516254\n",
            "Training Accuracy： 0.8549815517241379\n",
            "Epoch: 116\n",
            "Training loss: 1.5142315970662306\n",
            "Training Accuracy： 0.8557680341880342\n",
            "Epoch: 117\n",
            "Training loss: 1.514524839265877\n",
            "Training Accuracy： 0.856537966101695\n",
            "Epoch: 118\n",
            "Training loss: 1.5124146535878291\n",
            "Training Accuracy： 0.8573132773109243\n",
            "Epoch: 119\n",
            "Training loss: 1.5124436683971862\n",
            "Training Accuracy： 0.8580755\n",
            "Epoch: 120\n",
            "Training loss: 1.5115673365190512\n",
            "Training Accuracy： 0.8588302479338843\n",
            "Epoch: 121\n",
            "Training loss: 1.512916766469131\n",
            "Training Accuracy： 0.8595614754098361\n",
            "Epoch: 122\n",
            "Training loss: 1.513665636177258\n",
            "Training Accuracy： 0.8602760975609756\n",
            "Epoch: 123\n",
            "Training loss: 1.511478519500674\n",
            "Training Accuracy： 0.8609967741935484\n",
            "Epoch: 124\n",
            "Training loss: 1.5117590305445445\n",
            "Training Accuracy： 0.86170448\n",
            "Epoch: 125\n",
            "Training loss: 1.51328904839123\n",
            "Training Accuracy： 0.8623880952380952\n",
            "Epoch: 126\n",
            "Training loss: 1.5117325063251779\n",
            "Training Accuracy： 0.863075905511811\n",
            "Epoch: 127\n",
            "Training loss: 1.5112933409793297\n",
            "Training Accuracy： 0.863754375\n",
            "Epoch: 128\n",
            "Training loss: 1.5112115756020217\n",
            "Training Accuracy： 0.8644226356589148\n",
            "Epoch: 129\n",
            "Training loss: 1.5104297701355136\n",
            "Training Accuracy： 0.8650853846153846\n",
            "Epoch: 130\n",
            "Training loss: 1.5096911179744983\n",
            "Training Accuracy： 0.865746106870229\n",
            "Epoch: 131\n",
            "Training loss: 1.509366786083602\n",
            "Training Accuracy： 0.8663963636363636\n",
            "Epoch: 132\n",
            "Training loss: 1.5082968650266642\n",
            "Training Accuracy： 0.8670481203007518\n",
            "Epoch: 133\n",
            "Training loss: 1.5089012888996192\n",
            "Training Accuracy： 0.8676829850746268\n",
            "Epoch: 134\n",
            "Training loss: 1.5080863531593167\n",
            "Training Accuracy： 0.8683155555555555\n",
            "Epoch: 135\n",
            "Training loss: 1.5077554668916766\n",
            "Training Accuracy： 0.8689411764705882\n",
            "Epoch: 136\n",
            "Training loss: 1.5077385057878616\n",
            "Training Accuracy： 0.8695578102189782\n",
            "Epoch: 137\n",
            "Training loss: 1.5063273321332225\n",
            "Training Accuracy： 0.8701752173913043\n",
            "Epoch: 138\n",
            "Training loss: 1.5053258026042557\n",
            "Training Accuracy： 0.8707920863309353\n",
            "Epoch: 139\n",
            "Training loss: 1.5062037386247873\n",
            "Training Accuracy： 0.871393\n",
            "Epoch: 140\n",
            "Training loss: 1.505686623208663\n",
            "Training Accuracy： 0.8719889361702128\n",
            "Epoch: 141\n",
            "Training loss: 1.505250669043997\n",
            "Training Accuracy： 0.8725788732394366\n",
            "Epoch: 142\n",
            "Training loss: 1.5048559181525578\n",
            "Training Accuracy： 0.8731641958041958\n",
            "Epoch: 143\n",
            "Training loss: 1.505183260916444\n",
            "Training Accuracy： 0.8737390277777778\n",
            "Epoch: 144\n",
            "Training loss: 1.504845594658571\n",
            "Training Accuracy： 0.8743073103448276\n",
            "Epoch: 145\n",
            "Training loss: 1.5044609047567752\n",
            "Training Accuracy： 0.874871095890411\n",
            "Epoch: 146\n",
            "Training loss: 1.508109660557164\n",
            "Training Accuracy： 0.8754024489795919\n",
            "Epoch: 147\n",
            "Training loss: 1.510256828554451\n",
            "Training Accuracy： 0.8759131081081081\n",
            "Epoch: 148\n",
            "Training loss: 1.5055761940948797\n",
            "Training Accuracy： 0.8764475167785235\n",
            "Epoch: 149\n",
            "Training loss: 1.5047162803237701\n",
            "Training Accuracy： 0.8769806666666666\n",
            "Epoch: 150\n",
            "Training loss: 1.5039503124668776\n",
            "Training Accuracy： 0.8775117880794702\n",
            "Epoch: 151\n",
            "Training loss: 1.5033144687142823\n",
            "Training Accuracy： 0.8780388157894737\n",
            "Epoch: 152\n",
            "Training loss: 1.5032056518222974\n",
            "Training Accuracy： 0.8785623529411765\n",
            "Epoch: 153\n",
            "Training loss: 1.5021849625250872\n",
            "Training Accuracy： 0.879084025974026\n",
            "Epoch: 154\n",
            "Training loss: 1.5039145923636454\n",
            "Training Accuracy： 0.8795883870967742\n",
            "Epoch: 155\n",
            "Training loss: 1.5022530802680403\n",
            "Training Accuracy： 0.8800966666666666\n",
            "Epoch: 156\n",
            "Training loss: 1.5015121338617465\n",
            "Training Accuracy： 0.8806019108280255\n",
            "Epoch: 157\n",
            "Training loss: 1.5023160680480625\n",
            "Training Accuracy： 0.881097088607595\n",
            "Epoch: 158\n",
            "Training loss: 1.5006436330583088\n",
            "Training Accuracy： 0.8815967295597484\n",
            "Epoch: 159\n",
            "Training loss: 1.5011708262326466\n",
            "Training Accuracy： 0.8820875\n",
            "Epoch: 160\n",
            "Training loss: 1.4999444894778453\n",
            "Training Accuracy： 0.8825793788819876\n",
            "Epoch: 161\n",
            "Training loss: 1.500353375206823\n",
            "Training Accuracy： 0.8830617283950617\n",
            "Epoch: 162\n",
            "Training loss: 1.4999623541027078\n",
            "Training Accuracy： 0.8835411042944785\n",
            "Epoch: 163\n",
            "Training loss: 1.4993078422058574\n",
            "Training Accuracy： 0.8840175609756098\n",
            "Epoch: 164\n",
            "Training loss: 1.4996948086697122\n",
            "Training Accuracy： 0.8844863030303031\n",
            "Epoch: 165\n",
            "Training loss: 1.500073376518991\n",
            "Training Accuracy： 0.8849471084337349\n",
            "Epoch: 166\n",
            "Training loss: 1.5004510464875593\n",
            "Training Accuracy： 0.8853997604790419\n",
            "Epoch: 167\n",
            "Training loss: 1.500063526356007\n",
            "Training Accuracy： 0.88585\n",
            "Epoch: 168\n",
            "Training loss: 1.4990759366918402\n",
            "Training Accuracy： 0.8863013017751479\n",
            "Epoch: 169\n",
            "Training loss: 1.4980725042350458\n",
            "Training Accuracy： 0.8867522352941176\n",
            "Epoch: 170\n",
            "Training loss: 1.4989786132827134\n",
            "Training Accuracy： 0.887193567251462\n",
            "Epoch: 171\n",
            "Training loss: 1.4973094568533056\n",
            "Training Accuracy： 0.8876393023255814\n",
            "Epoch: 172\n",
            "Training loss: 1.4986766672805143\n",
            "Training Accuracy： 0.8880708670520231\n",
            "Epoch: 173\n",
            "Training loss: 1.4978100014159748\n",
            "Training Accuracy： 0.8885028735632184\n",
            "Epoch: 174\n",
            "Training loss: 1.497620210775634\n",
            "Training Accuracy： 0.8889316571428572\n",
            "Epoch: 175\n",
            "Training loss: 1.497824662634174\n",
            "Training Accuracy： 0.889354659090909\n",
            "Epoch: 176\n",
            "Training loss: 1.4977085620850858\n",
            "Training Accuracy： 0.8897731073446328\n",
            "Epoch: 177\n",
            "Training loss: 1.4976221937352738\n",
            "Training Accuracy： 0.890187191011236\n",
            "Epoch: 178\n",
            "Training loss: 1.498081139896227\n",
            "Training Accuracy： 0.890593966480447\n",
            "Epoch: 179\n",
            "Training loss: 1.4983297220581329\n",
            "Training Accuracy： 0.8909948888888889\n",
            "Epoch: 180\n",
            "Training loss: 1.4976513097658182\n",
            "Training Accuracy： 0.8913954696132597\n",
            "Epoch: 181\n",
            "Training loss: 1.497354789310709\n",
            "Training Accuracy： 0.8917936263736264\n",
            "Epoch: 182\n",
            "Training loss: 1.4981564225443185\n",
            "Training Accuracy： 0.8921816393442623\n",
            "Epoch: 183\n",
            "Training loss: 1.4981680015468841\n",
            "Training Accuracy： 0.8925663043478261\n",
            "Epoch: 184\n",
            "Training loss: 1.4975722590675744\n",
            "Training Accuracy： 0.8929507027027027\n",
            "Epoch: 185\n",
            "Training loss: 1.4980910168889234\n",
            "Training Accuracy： 0.8933274193548387\n",
            "Epoch: 186\n",
            "Training loss: 1.4971983323011862\n",
            "Training Accuracy： 0.8937060962566845\n",
            "Epoch: 187\n",
            "Training loss: 1.496704346383624\n",
            "Training Accuracy： 0.8940826595744681\n",
            "Epoch: 188\n",
            "Training loss: 1.4966851985058212\n",
            "Training Accuracy： 0.8944551322751323\n",
            "Epoch: 189\n",
            "Training loss: 1.4959601983999657\n",
            "Training Accuracy： 0.8948276842105263\n",
            "Epoch: 190\n",
            "Training loss: 1.495597433708513\n",
            "Training Accuracy： 0.8951978010471204\n",
            "Epoch: 191\n",
            "Training loss: 1.4965656212223766\n",
            "Training Accuracy： 0.8955590625\n",
            "Epoch: 192\n",
            "Training loss: 1.4952066502607693\n",
            "Training Accuracy： 0.8959240414507772\n",
            "Epoch: 193\n",
            "Training loss: 1.4955912262887296\n",
            "Training Accuracy： 0.8962827835051547\n",
            "Epoch: 194\n",
            "Training loss: 1.4950058696519992\n",
            "Training Accuracy： 0.8966408205128205\n",
            "Epoch: 195\n",
            "Training loss: 1.4954104575964495\n",
            "Training Accuracy： 0.8969937755102041\n",
            "Epoch: 196\n",
            "Training loss: 1.4947762946643488\n",
            "Training Accuracy： 0.897346192893401\n",
            "Epoch: 197\n",
            "Training loss: 1.4946945800500757\n",
            "Training Accuracy： 0.8976949494949495\n",
            "Epoch: 198\n",
            "Training loss: 1.4951214528144778\n",
            "Training Accuracy： 0.8980369849246231\n",
            "Epoch: 199\n",
            "Training loss: 1.4953465560817962\n",
            "Training Accuracy： 0.8983765\n",
            "Epoch: 200\n",
            "Training loss: 1.4945847748795433\n",
            "Training Accuracy： 0.8987163184079602\n",
            "Epoch: 201\n",
            "Training loss: 1.494291661797887\n",
            "Training Accuracy： 0.8990532673267326\n",
            "Epoch: 202\n",
            "Training loss: 1.4941246733641076\n",
            "Training Accuracy： 0.8993881773399015\n",
            "Epoch: 203\n",
            "Training loss: 1.4930535350614191\n",
            "Training Accuracy： 0.8997243137254902\n",
            "Epoch: 204\n",
            "Training loss: 1.4942616434658276\n",
            "Training Accuracy： 0.9000521951219512\n",
            "Epoch: 205\n",
            "Training loss: 1.4940554306025395\n",
            "Training Accuracy： 0.9003769902912622\n",
            "Epoch: 206\n",
            "Training loss: 1.4931186259250202\n",
            "Training Accuracy： 0.9007044444444444\n",
            "Epoch: 207\n",
            "Training loss: 1.4940421067540297\n",
            "Training Accuracy： 0.9010242307692308\n",
            "Epoch: 208\n",
            "Training loss: 1.492978417507523\n",
            "Training Accuracy： 0.9013452631578948\n",
            "Epoch: 209\n",
            "Training loss: 1.4932864479091772\n",
            "Training Accuracy： 0.9016625714285714\n",
            "Epoch: 210\n",
            "Training loss: 1.4928502743811254\n",
            "Training Accuracy： 0.9019781042654028\n",
            "Epoch: 211\n",
            "Training loss: 1.4931202863183473\n",
            "Training Accuracy： 0.9022903773584906\n",
            "Epoch: 212\n",
            "Training loss: 1.492514653126602\n",
            "Training Accuracy： 0.9026018779342723\n",
            "Epoch: 213\n",
            "Training loss: 1.4924938655875224\n",
            "Training Accuracy： 0.9029106542056075\n",
            "Epoch: 214\n",
            "Training loss: 1.492667875631386\n",
            "Training Accuracy： 0.9032157209302326\n",
            "Epoch: 215\n",
            "Training loss: 1.4986805170393356\n",
            "Training Accuracy： 0.9034901851851852\n",
            "Epoch: 216\n",
            "Training loss: 1.4946488939282838\n",
            "Training Accuracy： 0.9037816589861751\n",
            "Epoch: 217\n",
            "Training loss: 1.4924846645206442\n",
            "Training Accuracy： 0.9040795412844037\n",
            "Epoch: 218\n",
            "Training loss: 1.4919014637122678\n",
            "Training Accuracy： 0.9043770776255707\n",
            "Epoch: 219\n",
            "Training loss: 1.4930405807312188\n",
            "Training Accuracy： 0.9046661818181818\n",
            "Epoch: 220\n",
            "Training loss: 1.4919199864272876\n",
            "Training Accuracy： 0.9049587330316742\n",
            "Epoch: 221\n",
            "Training loss: 1.4934781620569546\n",
            "Training Accuracy： 0.9052415315315315\n",
            "Epoch: 222\n",
            "Training loss: 1.4928479339460583\n",
            "Training Accuracy： 0.9055236771300449\n",
            "Epoch: 223\n",
            "Training loss: 1.4920351887907823\n",
            "Training Accuracy： 0.9058083035714286\n",
            "Epoch: 224\n",
            "Training loss: 1.4918576547556825\n",
            "Training Accuracy： 0.9060905777777778\n",
            "Epoch: 225\n",
            "Training loss: 1.4923115986997209\n",
            "Training Accuracy： 0.9063681415929203\n",
            "Epoch: 226\n",
            "Training loss: 1.4913694494215728\n",
            "Training Accuracy： 0.9066474008810572\n",
            "Epoch: 227\n",
            "Training loss: 1.4922796297256293\n",
            "Training Accuracy： 0.906919298245614\n",
            "Epoch: 228\n",
            "Training loss: 1.4917142011625382\n",
            "Training Accuracy： 0.9071926637554585\n",
            "Epoch: 229\n",
            "Training loss: 1.4901087374028648\n",
            "Training Accuracy： 0.9074700869565218\n",
            "Epoch: 230\n",
            "Training loss: 1.491370461023677\n",
            "Training Accuracy： 0.907740606060606\n",
            "Epoch: 231\n",
            "Training loss: 1.4914377418625386\n",
            "Training Accuracy： 0.9080087931034483\n",
            "Epoch: 232\n",
            "Training loss: 1.490183246562548\n",
            "Training Accuracy： 0.9082788841201717\n",
            "Epoch: 233\n",
            "Training loss: 1.4907766435762195\n",
            "Training Accuracy： 0.9085449572649573\n",
            "Epoch: 234\n",
            "Training loss: 1.4895275361702571\n",
            "Training Accuracy： 0.9088131063829787\n",
            "Epoch: 235\n",
            "Training loss: 1.4901801523040323\n",
            "Training Accuracy： 0.9090761016949153\n",
            "Epoch: 236\n",
            "Training loss: 1.490070711011472\n",
            "Training Accuracy： 0.9093375527426161\n",
            "Epoch: 237\n",
            "Training loss: 1.4896895644609884\n",
            "Training Accuracy： 0.9095982352941177\n",
            "Epoch: 238\n",
            "Training loss: 1.4892570778841863\n",
            "Training Accuracy： 0.9098594979079498\n",
            "Epoch: 239\n",
            "Training loss: 1.4896638115958485\n",
            "Training Accuracy： 0.9101160833333334\n",
            "Epoch: 240\n",
            "Training loss: 1.4896150662770966\n",
            "Training Accuracy： 0.9103710373443984\n",
            "Epoch: 241\n",
            "Training loss: 1.4895080649639334\n",
            "Training Accuracy： 0.9106241322314049\n",
            "Epoch: 242\n",
            "Training loss: 1.4900935075776962\n",
            "Training Accuracy： 0.9108731687242798\n",
            "Epoch: 243\n",
            "Training loss: 1.4903252432718301\n",
            "Training Accuracy： 0.9111191803278689\n",
            "Epoch: 244\n",
            "Training loss: 1.488914933960761\n",
            "Training Accuracy： 0.9113688163265307\n",
            "Epoch: 245\n",
            "Training loss: 1.4888413530176559\n",
            "Training Accuracy： 0.9116169918699187\n",
            "Epoch: 246\n",
            "Training loss: 1.4900336940880017\n",
            "Training Accuracy： 0.9118576518218624\n",
            "Epoch: 247\n",
            "Training loss: 1.4895425056252638\n",
            "Training Accuracy： 0.9120982258064516\n",
            "Epoch: 248\n",
            "Training loss: 1.4898675626805982\n",
            "Training Accuracy： 0.9123355020080322\n",
            "Epoch: 249\n",
            "Training loss: 1.4896973519374037\n",
            "Training Accuracy： 0.91257144\n",
            "Epoch: 250\n",
            "Training loss: 1.4897064493440302\n",
            "Training Accuracy： 0.9128064541832669\n",
            "Epoch: 251\n",
            "Training loss: 1.4900786651064977\n",
            "Training Accuracy： 0.9130374603174604\n",
            "Epoch: 252\n",
            "Training loss: 1.490299111741888\n",
            "Training Accuracy： 0.9132659288537549\n",
            "Epoch: 253\n",
            "Training loss: 1.4892927303033716\n",
            "Training Accuracy： 0.9134966929133859\n",
            "Epoch: 254\n",
            "Training loss: 1.4903450272882077\n",
            "Training Accuracy： 0.9137209411764706\n",
            "Epoch: 255\n",
            "Training loss: 1.488698592728666\n",
            "Training Accuracy： 0.913950390625\n",
            "Epoch: 256\n",
            "Training loss: 1.4890792542101476\n",
            "Training Accuracy： 0.9141771206225681\n",
            "Epoch: 257\n",
            "Training loss: 1.4885594937807458\n",
            "Training Accuracy： 0.9144033333333333\n",
            "Epoch: 258\n",
            "Training loss: 1.4882943343628399\n",
            "Training Accuracy： 0.9146285714285715\n",
            "Epoch: 259\n",
            "Training loss: 1.4878892659226342\n",
            "Training Accuracy： 0.9148544615384615\n",
            "Epoch: 260\n",
            "Training loss: 1.4890009408716656\n",
            "Training Accuracy： 0.9150742528735633\n",
            "Epoch: 261\n",
            "Training loss: 1.488488309066314\n",
            "Training Accuracy： 0.9152941984732824\n",
            "Epoch: 262\n",
            "Training loss: 1.4881835441150324\n",
            "Training Accuracy： 0.9155136121673004\n",
            "Epoch: 263\n",
            "Training loss: 1.487757298037829\n",
            "Training Accuracy： 0.9157328787878788\n",
            "Epoch: 264\n",
            "Training loss: 1.487804907209733\n",
            "Training Accuracy： 0.9159501132075472\n",
            "Epoch: 265\n",
            "Training loss: 1.4884695421399363\n",
            "Training Accuracy： 0.9161635338345865\n",
            "Epoch: 266\n",
            "Training loss: 1.489114720650646\n",
            "Training Accuracy： 0.9163722846441947\n",
            "Epoch: 267\n",
            "Training loss: 1.4878199502940068\n",
            "Training Accuracy： 0.9165841791044776\n",
            "Epoch: 268\n",
            "Training loss: 1.487777074432129\n",
            "Training Accuracy： 0.9167949442379182\n",
            "Epoch: 269\n",
            "Training loss: 1.4880812915084918\n",
            "Training Accuracy： 0.9170034814814815\n",
            "Epoch: 270\n",
            "Training loss: 1.4889460699942412\n",
            "Training Accuracy： 0.9172070848708487\n",
            "Epoch: 271\n",
            "Training loss: 1.4884048241483585\n",
            "Training Accuracy： 0.9174113970588236\n",
            "Epoch: 272\n",
            "Training loss: 1.487710618454477\n",
            "Training Accuracy： 0.9176167032967033\n",
            "Epoch: 273\n",
            "Training loss: 1.4886374372960356\n",
            "Training Accuracy： 0.9178172992700729\n",
            "Epoch: 274\n",
            "Training loss: 1.488504768027674\n",
            "Training Accuracy： 0.9180167272727273\n",
            "Epoch: 275\n",
            "Training loss: 1.4875874092511814\n",
            "Training Accuracy： 0.9182177536231884\n",
            "Epoch: 276\n",
            "Training loss: 1.4877462986180239\n",
            "Training Accuracy： 0.9184163176895307\n",
            "Epoch: 277\n",
            "Training loss: 1.487850849890648\n",
            "Training Accuracy： 0.9186140287769784\n",
            "Epoch: 278\n",
            "Training loss: 1.4885067656217024\n",
            "Training Accuracy： 0.9188078853046595\n",
            "Epoch: 279\n",
            "Training loss: 1.4878053119420396\n",
            "Training Accuracy： 0.9190020714285714\n",
            "Epoch: 280\n",
            "Training loss: 1.4879844824371435\n",
            "Training Accuracy： 0.9191947330960855\n",
            "Epoch: 281\n",
            "Training loss: 1.4873959509003194\n",
            "Training Accuracy： 0.9193878723404255\n",
            "Epoch: 282\n",
            "Training loss: 1.4869984807565695\n",
            "Training Accuracy： 0.9195816961130742\n",
            "Epoch: 283\n",
            "Training loss: 1.4878789930392409\n",
            "Training Accuracy： 0.9197704929577465\n",
            "Epoch: 284\n",
            "Training loss: 1.486989189291854\n",
            "Training Accuracy： 0.9199616842105263\n",
            "Epoch: 285\n",
            "Training loss: 1.4875281433315228\n",
            "Training Accuracy： 0.9201497202797203\n",
            "Epoch: 286\n",
            "Training loss: 1.487113787085199\n",
            "Training Accuracy： 0.9203371428571429\n",
            "Epoch: 287\n",
            "Training loss: 1.4872387781777345\n",
            "Training Accuracy： 0.9205231944444444\n",
            "Epoch: 288\n",
            "Training loss: 1.4881349286764785\n",
            "Training Accuracy： 0.920704982698962\n",
            "Epoch: 289\n",
            "Training loss: 1.4870834115825955\n",
            "Training Accuracy： 0.9208893793103449\n",
            "Epoch: 290\n",
            "Training loss: 1.4864149822298522\n",
            "Training Accuracy： 0.9210742268041238\n",
            "Epoch: 291\n",
            "Training loss: 1.4861446379700585\n",
            "Training Accuracy： 0.9212590410958904\n",
            "Epoch: 292\n",
            "Training loss: 1.4869865849804695\n",
            "Training Accuracy： 0.92144\n",
            "Epoch: 293\n",
            "Training loss: 1.4859032900741949\n",
            "Training Accuracy： 0.921622925170068\n",
            "Epoch: 294\n",
            "Training loss: 1.4868453460581161\n",
            "Training Accuracy： 0.9218014915254237\n",
            "Epoch: 295\n",
            "Training loss: 1.4860209234230353\n",
            "Training Accuracy： 0.9219816891891892\n",
            "Epoch: 296\n",
            "Training loss: 1.4870207489603926\n",
            "Training Accuracy： 0.9221573063973064\n",
            "Epoch: 297\n",
            "Training loss: 1.4866060840199367\n",
            "Training Accuracy： 0.9223328187919463\n",
            "Epoch: 298\n",
            "Training loss: 1.4864477743882962\n",
            "Training Accuracy： 0.9225082943143813\n",
            "Epoch: 299\n",
            "Training loss: 1.486477305669614\n",
            "Training Accuracy： 0.9226818\n",
            "Total Training Accuracy： 0.9226818\n",
            "finished training!\n",
            "time: 1h 18min 19s (started: 2022-10-13 18:49:26 +00:00)\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "for epoch in range(epochs):\n",
        "    train_loss = []\n",
        "    for i, data in enumerate(trainLoader):\n",
        "        img, label = data\n",
        "        img, label = img.to(device), label.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(img)\n",
        "        lossValue = criterion(outputs, label)\n",
        "        lossValue.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss.append(lossValue.item())\n",
        "        train_lossMean = statistics.mean(train_loss)\n",
        "        \n",
        "        _, pred = torch.max(outputs.data, 1)\n",
        "        correct += (pred == label).sum().item()\n",
        "        total += label.size(0)\n",
        "    \n",
        "    print(\"Epoch:\", epoch)\n",
        "    print(\"Training loss:\", train_lossMean)\n",
        "    print(\"Training Accuracy：\", correct / total)\n",
        "\n",
        "print(\"Total Training Accuracy：\", correct / total)\n",
        "print(\"finished training!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLGzrtWl1jMr"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4xXE2Aq1jMr",
        "outputId": "c72487e9-21d6-4357-be67-38ed4e7d20f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Accuracy： 0.7868\n",
            "time: 2.17 s (started: 2022-10-13 20:08:20 +00:00)\n"
          ]
        }
      ],
      "source": [
        "net.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testLoader:\n",
        "        img, label = data\n",
        "        img, label = img.to(device), label.to(device)\n",
        "        outputs = net(img)\n",
        "        _, pred = torch.max(outputs, 1)\n",
        "        total += label.size(0)\n",
        "        correct += (pred == label).sum().item()\n",
        "\n",
        "print(\"Testing Accuracy：\", correct / total)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy and runtime can be seen here: https://docs.google.com/spreadsheets/d/1D0GpWYBjbrE6r6jhNcbuuhn3rh9vNXij/edit?usp=sharing&ouid=110592934452569340029&rtpof=true&sd=true"
      ],
      "metadata": {
        "id": "iphO5119GWrs"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "40fa23e76a6344ec8fe6a4067eca83a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1837ad39e8c434b86622ac976a92e77",
              "IPY_MODEL_9ac5984964404b26ba9a9d25c9eabd93",
              "IPY_MODEL_28fd8e4bf8bb4677ac7090f88f4a14e6"
            ],
            "layout": "IPY_MODEL_de9bff3824184c65b9d1ae0a03efc1e3"
          }
        },
        "e1837ad39e8c434b86622ac976a92e77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1e407706fda40bcb3f426deebdd6684",
            "placeholder": "​",
            "style": "IPY_MODEL_1464a97c17584973984171f3c8ab5b60",
            "value": "100%"
          }
        },
        "9ac5984964404b26ba9a9d25c9eabd93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0737c44cc61042f08fdbebc6ce6860d9",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66d2f83990984ad0a29af087a2c33c5f",
            "value": 170498071
          }
        },
        "28fd8e4bf8bb4677ac7090f88f4a14e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8560627d398421abc117c34b7ee3ce1",
            "placeholder": "​",
            "style": "IPY_MODEL_0d44dad3ce1e4528bf1a80f2ac886599",
            "value": " 170498071/170498071 [00:05&lt;00:00, 33241477.93it/s]"
          }
        },
        "de9bff3824184c65b9d1ae0a03efc1e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1e407706fda40bcb3f426deebdd6684": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1464a97c17584973984171f3c8ab5b60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0737c44cc61042f08fdbebc6ce6860d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66d2f83990984ad0a29af087a2c33c5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8560627d398421abc117c34b7ee3ce1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d44dad3ce1e4528bf1a80f2ac886599": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}